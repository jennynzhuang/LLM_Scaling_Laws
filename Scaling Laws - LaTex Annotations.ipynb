{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18276011-78d3-4a6f-af1c-19b6d9705131",
   "metadata": {},
   "source": [
    "## Individual Presentation - Research Paper\n",
    "Jennifer Zhuang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c361718-73e1-4056-ac4e-09d2a4c88ff2",
   "metadata": {},
   "source": [
    "### Equation for Cross-Entropy Loss\n",
    "For a sequence of $N$ tokens:\n",
    "\n",
    "$$L = - \\frac{1}{N} \\sum_{i=1}^N \\log p(y_i | y_{<i})$$\n",
    "$Where:$\n",
    " \n",
    "$y_i: \\text{The } i^{th} \\text { token in the sequence}$\n",
    " \n",
    "$p(y_i | y_{<i}): \\text{The model's predicted probability of token } y_i$\n",
    "$\\text{given all previous tokens in the sequence (} y_{<i} \\text{)}$\n",
    " \n",
    "$\\text{The loss is averaged over all tokens in the sequence}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ec376-37ee-4e4b-bcc0-fa294fdf3d04",
   "metadata": {},
   "source": [
    "### Power Laws\n",
    "$$\n",
    "L(X) \\propto \\frac{1}{X^{\\alpha_X}}$$\n",
    "---\n",
    "$$\\alpha_X: \\text{Scaling exponent that determines}$$\n",
    "$$\\text{how quickly loss decreases as } X \\text{ grows}$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70934689-628f-4360-b066-40707db52142",
   "metadata": {},
   "source": [
    "### Scaling Factors\n",
    "| **Factor**        | **Range/Details**                           |\n",
    "|--------------------|---------------------------------------------|\n",
    "| **Model Size**     | 768 to 1.5 billion parameters              |\n",
    "| **Dataset Size**   | 22 million to 23 billion tokens            |\n",
    "| **Shape**          | Depth, width, attention heads, feed-forward |\n",
    "| **Context Length** | 1024 tokens (default), shorter contexts    |\n",
    "| **Batch Size**     | $2^19$, varied for experiments        |\n",
    "\n",
    "### Scaling Factors\n",
    "\n",
    "| **Factor**          | **Range/Details**                                                                                        | **Notation**                                                                                          |\n",
    "|----------------------|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| **Model Size**       | 768 to 1.5 billion parameters                                                                            | $N$                   |\n",
    "| **Dataset Size**     | 22 million to 23 billion tokens                                                                         | $D$                                                                   |\n",
    "| **Shape**            | Depth, width, attention heads, feed-forward dimensions                                                 |  $d_{ff}$, $n_{layer}$, $n_{heads}$                                                                           |\n",
    "| **Context Length**   | 1024 tokens (default), shorter contexts                                                                | $n_{ctx}$                                                                                                    |\n",
    "| **Batch Size**       | $2^{19}$, varied for experiments                                                                   | $B$                                                                                 |\n",
    "| **Training Compute** | Estimated as $C \\approx 6NBS$, quoted in PF-days (1 PF-day = $ 8.64 \\times 10^{19}$ FLOPs)       | $C$                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367bcec-c484-4382-8d62-89ed29779cf2",
   "metadata": {},
   "source": [
    "### Paramaterizing Transformers\n",
    "Given:\n",
    "- $n_{layer}: \\text{ Number of layers}$\n",
    "- $d_{model}:\\text{ Dimension of the residual stream (main data flow)}$\n",
    "- $d_{ff}:\\text{ Dimension of the intermediate feed-forward layer}$\n",
    "- $d_{attn}:\\text{ Dimension of the attention output}$\n",
    "- $n_{heads}:\\text{ Number of attention heads per layer}$\n",
    "\n",
    "#### Defining Model Size\n",
    "\n",
    "We use **N** to denote the model size, defined as the number of non-embedding parameters:\n",
    "$$N \\approx 2 \\cdot d_{\\text{model}} \\cdot n_{\\text{layer}} \\cdot (2 \\cdot d_{\\text{attn}} + d_{\\text{ff}})$$\n",
    "\n",
    "This simplifies to:\n",
    "$$N = 12 \\cdot n_{\\text{layer}} \\cdot d_{\\text{model}}^2$$\n",
    "$$\\text{where } d_{\\text{model}} = \\frac{d_{\\text{ff}}}{4} = d_{\\text{attn}}$$\n",
    "\n",
    "\n",
    "\n",
    "## Compute for a Forward Pass\n",
    "\n",
    "Evaluating a **forward pass** of the Transformer requires approximately:\n",
    "$C_{\\text{forward}} \\approx 2 \\cdot N + 2 \\cdot n_{\\text{layer}} \\cdot n_{\\text{ctx}} \\cdot d_{\\text{model}}$\n",
    "\n",
    "## Model Shape Definition \n",
    "- $n_{layer}: \\text{ Number of layers}$\n",
    "- $d_{ff}:\\text{ Dimension of the intermediate feed-forward layer}$\n",
    "- $n_{heads}:\\text{ Number of attention heads per layer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdf81e-079f-4428-b1e8-40d45244a5cf",
   "metadata": {},
   "source": [
    "$$L = \\left( \\frac{C_{\\text{min}}}{2.3 \\times 10^8} \\right)^{-0.050}$$\n",
    "- $C_{\\text{min}}$: The minimum compute required to achieve a specific loss value.\n",
    "- The exponent ($-0.050$) indicates how quickly the loss decreases as compute increases.\n",
    "- The dashed line demonstrates that loss scales predictably with compute, following a power-law relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7450b-08e8-40c1-a84b-f7252e2bf2b1",
   "metadata": {},
   "source": [
    "$$L = \\left( \\frac{D}{5.4 \\times 10^{13}} \\right)^{-0.095}$$\n",
    "\n",
    "$$L = \\left( \\frac{N}{8.8 \\times 10^{13}} \\right)^{-0.076}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d6e73-3ee7-4e62-9cdc-fd75f2baaaff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "en685648"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
